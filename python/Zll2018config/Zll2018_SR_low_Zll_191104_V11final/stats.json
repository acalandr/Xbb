[{"loss_train_training": 0.13631250314079782, "loss_test": 0.11664572622444706, "loss_train": 0.11410968625731302, "significance_test": 1.8290671145976252, "epochs": 1, "steps": 3005, "time": 5.0067901611328125e-06, "significance_train": 1.8138292530678752}, {"epochs": 2, "loss_train_training": 0.11914715952737359, "steps": 6010, "loss_test": 0.11301579234503589, "time": 166.82832503318787, "loss_train": 0.11109233727377565}, {"epochs": 3, "loss_train_training": 0.1177724259107462, "steps": 9015, "loss_test": 0.11175907527426351, "time": 285.31323313713074, "loss_train": 0.10936830462263342}, {"epochs": 4, "loss_train_training": 0.11623798271210341, "steps": 12020, "loss_test": 0.11148584582485697, "time": 402.03231596946716, "loss_train": 0.10860105887898333}, {"epochs": 5, "loss_train_training": 0.11582044554803018, "steps": 15025, "loss_test": 0.11110528544218629, "time": 518.6009740829468, "loss_train": 0.10842201205415933}, {"epochs": 6, "loss_train_training": 0.11513083772284417, "steps": 18030, "loss_test": 0.11119609454977311, "time": 636.5131950378418, "loss_train": 0.10803358634030807}, {"epochs": 7, "loss_train_training": 0.11429454208585664, "steps": 21035, "loss_test": 0.11088840124640582, "time": 753.0394639968872, "loss_train": 0.1081797917585844}, {"epochs": 8, "loss_train_training": 0.11401875919713554, "steps": 24040, "loss_test": 0.10992397126061632, "time": 869.9515261650085, "loss_train": 0.10672728792614969}, {"epochs": 9, "loss_train_training": 0.11403713352643512, "steps": 27045, "loss_test": 0.11082002786731301, "time": 988.0172920227051, "loss_train": 0.10747340662735753}, {"epochs": 10, "loss_train_training": 0.11362772326600333, "steps": 30050, "loss_test": 0.10980593894818648, "time": 1105.027235031128, "loss_train": 0.10652115729000637}, {"epochs": 11, "loss_train_training": 0.11143760976893766, "steps": 31552, "loss_test": 0.10888395941726749, "time": 1223.159469127655, "loss_train": 0.10524117853387431}, {"epochs": 12, "loss_train_training": 0.11086736451065572, "steps": 33054, "loss_test": 0.1090054668065015, "time": 1334.159733057022, "loss_train": 0.10535062498526938}, {"epochs": 13, "loss_train_training": 0.11090705790042321, "steps": 34556, "loss_test": 0.10953089490365919, "time": 1445.4135739803314, "loss_train": 0.10544167809172988}, {"epochs": 14, "loss_train_training": 0.11096260975922313, "steps": 36058, "loss_test": 0.10890498169225821, "time": 1557.7446429729462, "loss_train": 0.10480433098779374}, {"epochs": 15, "loss_train_training": 0.11050555786085668, "steps": 37560, "loss_test": 0.11023006873213834, "time": 1669.0199890136719, "loss_train": 0.10608622477047078}, {"epochs": 16, "loss_train_training": 0.1102467055088988, "steps": 39062, "loss_test": 0.10791087881620802, "time": 1781.2112390995026, "loss_train": 0.10400376227477619}, {"epochs": 17, "loss_train_training": 0.11026287812258448, "steps": 40564, "loss_test": 0.10833770358385332, "time": 1893.4006040096283, "loss_train": 0.10419522699813502}, {"epochs": 18, "loss_train_training": 0.10944476802789975, "steps": 42066, "loss_test": 0.10822753417271946, "time": 2004.8172509670258, "loss_train": 0.10406054917330813}, {"epochs": 19, "loss_train_training": 0.10999610094718149, "steps": 43568, "loss_test": 0.10715785673874945, "time": 2117.4179151058197, "loss_train": 0.10306854566362997}, {"epochs": 20, "loss_train_training": 0.10977059325448842, "steps": 45070, "loss_test": 0.1078813996093228, "time": 2229.51221203804, "loss_train": 0.10353059612230485}, {"loss_train_training": 0.10857733184305551, "loss_test": 0.10719343823627692, "loss_train": 0.10245377327437576, "significance_test": 1.9204136068664805, "epochs": 21, "steps": 45821, "time": 2341.206038951874, "significance_train": 2.045984046943252}, {"epochs": 22, "loss_train_training": 0.10769687178290478, "steps": 46572, "loss_test": 0.1069946786881944, "time": 2501.212818145752, "loss_train": 0.10240155850658306}, {"epochs": 23, "loss_train_training": 0.10827622449548838, "steps": 47323, "loss_test": 0.10684060759364042, "time": 2608.5795850753784, "loss_train": 0.1021654755450358}, {"epochs": 24, "loss_train_training": 0.1081155279524793, "steps": 48074, "loss_test": 0.10709717902809374, "time": 2717.103989124298, "loss_train": 0.10218125684267142}, {"epochs": 25, "loss_train_training": 0.10795709306247701, "steps": 48825, "loss_test": 0.10696737555557945, "time": 2824.7253971099854, "loss_train": 0.1018276736146836}, {"epochs": 26, "loss_train_training": 0.10777912848441801, "steps": 49576, "loss_test": 0.10646166244559588, "time": 2932.39231300354, "loss_train": 0.10151748160368576}, {"epochs": 27, "loss_train_training": 0.10781520494965516, "steps": 50327, "loss_test": 0.10651783778949854, "time": 3041.4905309677124, "loss_train": 0.10145989496918068}, {"epochs": 28, "loss_train_training": 0.10795408701610947, "steps": 51078, "loss_test": 0.10717751648781741, "time": 3148.6752541065216, "loss_train": 0.10160109525322576}, {"epochs": 29, "loss_train_training": 0.10753264808940506, "steps": 51829, "loss_test": 0.10609355396266722, "time": 3256.5341391563416, "loss_train": 0.10108528308378534}, {"epochs": 30, "loss_train_training": 0.10759055208707459, "steps": 52580, "loss_test": 0.10705034287072686, "time": 3365.8067400455475, "loss_train": 0.1019990718817256}, {"epochs": 31, "loss_train_training": 0.10749581345070536, "steps": 53331, "loss_test": 0.10657858624643546, "time": 3473.561952114105, "loss_train": 0.10114936451634068}, {"epochs": 32, "loss_train_training": 0.107530012706942, "steps": 54082, "loss_test": 0.10655304981658473, "time": 3581.3886029720306, "loss_train": 0.10121640058686761}, {"epochs": 33, "loss_train_training": 0.10726718346621797, "steps": 54833, "loss_test": 0.10623900886085927, "time": 3690.465562105179, "loss_train": 0.10091728368321223}, {"epochs": 34, "loss_train_training": 0.10716954188126222, "steps": 55584, "loss_test": 0.10648789496823771, "time": 3798.3675820827484, "loss_train": 0.10095572243981067}, {"epochs": 35, "loss_train_training": 0.10679801302489524, "steps": 56335, "loss_test": 0.10613240163820144, "time": 3907.097265958786, "loss_train": 0.10054431680514324}, {"epochs": 36, "loss_train_training": 0.10690103186549899, "steps": 57086, "loss_test": 0.10715879846434702, "time": 4014.963629961014, "loss_train": 0.10125337504108237}, {"epochs": 37, "loss_train_training": 0.10631569832087198, "steps": 57837, "loss_test": 0.10654754435347764, "time": 4122.621861934662, "loss_train": 0.10062779818926323}, {"epochs": 38, "loss_train_training": 0.10704651170381693, "steps": 58588, "loss_test": 0.10670317101952428, "time": 4231.487128019333, "loss_train": 0.1009608026437805}, {"epochs": 39, "loss_train_training": 0.10721376796219542, "steps": 59339, "loss_test": 0.10630310356407158, "time": 4338.909449100494, "loss_train": 0.10037740298733129}, {"epochs": 40, "loss_train_training": 0.10620910829099295, "steps": 60090, "loss_test": 0.10581750562261245, "time": 4446.524197101593, "loss_train": 0.09984642399768187}, {"loss_train_training": 0.1057287058432897, "loss_test": 0.10563015472618723, "loss_train": 0.09954515375995364, "significance_test": 1.894777709888504, "epochs": 41, "steps": 60465, "time": 4555.727713108063, "significance_train": 2.132854184000066}, {"epochs": 42, "loss_train_training": 0.10563436609506607, "steps": 60840, "loss_test": 0.10570731662518547, "time": 4712.251794099808, "loss_train": 0.09922411739045318}, {"epochs": 43, "loss_train_training": 0.10555059911807378, "steps": 61215, "loss_test": 0.10586158593428843, "time": 4818.794077157974, "loss_train": 0.09921717215119566}, {"epochs": 44, "loss_train_training": 0.10565936195850373, "steps": 61590, "loss_test": 0.1055187090389449, "time": 4924.11692404747, "loss_train": 0.0990333720628307}, {"epochs": 45, "loss_train_training": 0.10554263538122177, "steps": 61965, "loss_test": 0.10556227557149375, "time": 5029.266664028168, "loss_train": 0.09909680941240726}, {"epochs": 46, "loss_train_training": 0.1053967737754186, "steps": 62340, "loss_test": 0.10553975231602705, "time": 5135.890553951263, "loss_train": 0.09920510618321805}, {"epochs": 47, "loss_train_training": 0.10535598164796829, "steps": 62715, "loss_test": 0.10536240825113073, "time": 5241.293123006821, "loss_train": 0.0989996653765355}, {"epochs": 48, "loss_train_training": 0.10563183669249217, "steps": 63090, "loss_test": 0.10560174250792609, "time": 5346.793039083481, "loss_train": 0.09919392980928037}, {"epochs": 49, "loss_train_training": 0.10510888653993607, "steps": 63465, "loss_test": 0.10532162644160695, "time": 5453.513659954071, "loss_train": 0.09873979074235545}, {"epochs": 50, "loss_train_training": 0.10526347464323044, "steps": 63840, "loss_test": 0.10563493664208505, "time": 5558.595695972443, "loss_train": 0.09903273038881526}, {"epochs": 51, "loss_train_training": 0.10494200291236241, "steps": 64215, "loss_test": 0.10536978149045677, "time": 5663.830321073532, "loss_train": 0.09887877459109926}, {"epochs": 52, "loss_train_training": 0.10502887497345606, "steps": 64590, "loss_test": 0.10588428068300641, "time": 5770.5521030426025, "loss_train": 0.09935158757165663}, {"epochs": 53, "loss_train_training": 0.1056402794122696, "steps": 64965, "loss_test": 0.10544472169120016, "time": 5875.671350955963, "loss_train": 0.09873385942834083}, {"epochs": 54, "loss_train_training": 0.10517268244425455, "steps": 65340, "loss_test": 0.10536499322466482, "time": 5981.003028154373, "loss_train": 0.09849063429172253}, {"epochs": 55, "loss_train_training": 0.1051036471525828, "steps": 65715, "loss_test": 0.10581565001173722, "time": 6087.247380018234, "loss_train": 0.09850069673535937}, {"epochs": 56, "loss_train_training": 0.10523154922326405, "steps": 66090, "loss_test": 0.10524387379387708, "time": 6192.4396879673, "loss_train": 0.09837679407191935}, {"epochs": 57, "loss_train_training": 0.10472590372959772, "steps": 66465, "loss_test": 0.10566093707252261, "time": 6298.693170070648, "loss_train": 0.09857584254523741}, {"epochs": 58, "loss_train_training": 0.10455158646901448, "steps": 66840, "loss_test": 0.10535400888667877, "time": 6404.039588928223, "loss_train": 0.09829609555160128}, {"epochs": 59, "loss_train_training": 0.1048106871843338, "steps": 67215, "loss_test": 0.10556362243915136, "time": 6509.440421104431, "loss_train": 0.0981616657589734}, {"epochs": 60, "loss_train_training": 0.10484256100654601, "steps": 67590, "loss_test": 0.1052347984363281, "time": 6616.113772153854, "loss_train": 0.09827854072457916}, {"loss_train_training": 0.10384096723535786, "loss_test": 0.10483003955228395, "loss_train": 0.09770533400052211, "significance_test": 1.9005745759527528, "epochs": 61, "steps": 67636, "time": 6721.595098018646, "significance_train": 2.1910061922362374}, {"epochs": 62, "loss_train_training": 0.10347264956520952, "steps": 67682, "loss_test": 0.10491755991171794, "time": 6879.452677965164, "loss_train": 0.09755740932394641}, {"epochs": 63, "loss_train_training": 0.10335699857577034, "steps": 67728, "loss_test": 0.10489330400072865, "time": 6986.696838140488, "loss_train": 0.09739775579927246}, {"epochs": 64, "loss_train_training": 0.10357767829428548, "steps": 67774, "loss_test": 0.10484223558369397, "time": 7092.869341135025, "loss_train": 0.09729597933149654}, {"epochs": 65, "loss_train_training": 0.10319208224182544, "steps": 67820, "loss_test": 0.10477252174934942, "time": 7200.078884124756, "loss_train": 0.09718360370679213}, {"epochs": 66, "loss_train_training": 0.10359610017874966, "steps": 67866, "loss_test": 0.10470359628937526, "time": 7306.498471021652, "loss_train": 0.09710224615077873}, {"epochs": 67, "loss_train_training": 0.10327219266606413, "steps": 67912, "loss_test": 0.1047046769365074, "time": 7412.831330060959, "loss_train": 0.0970468765491289}, {"epochs": 68, "loss_train_training": 0.10298642953452856, "steps": 67958, "loss_test": 0.10475732511739169, "time": 7520.421669960022, "loss_train": 0.09695685860801755}, {"epochs": 69, "loss_train_training": 0.10320146835368613, "steps": 68004, "loss_test": 0.10468199688981045, "time": 7627.138921022415, "loss_train": 0.09696662234202005}, {"epochs": 70, "loss_train_training": 0.10294387586738753, "steps": 68050, "loss_test": 0.10496893313666768, "time": 7733.666986942291, "loss_train": 0.09700880821743588}, {"epochs": 71, "loss_train_training": 0.10294898097281871, "steps": 68096, "loss_test": 0.10492650892311602, "time": 7841.102488994598, "loss_train": 0.09688854544105895}, {"epochs": 72, "loss_train_training": 0.1029964008409044, "steps": 68142, "loss_test": 0.10481467620520082, "time": 7947.59880399704, "loss_train": 0.09682013953792043}, {"epochs": 73, "loss_train_training": 0.10339644259732703, "steps": 68188, "loss_test": 0.10493672274900023, "time": 8054.181782007217, "loss_train": 0.09691603383698197}, {"epochs": 74, "loss_train_training": 0.10321377023406651, "steps": 68234, "loss_test": 0.10477713784540152, "time": 8161.951508998871, "loss_train": 0.09681027995253223}, {"epochs": 75, "loss_train_training": 0.10330429154893626, "steps": 68280, "loss_test": 0.1048424377946625, "time": 8268.287193059921, "loss_train": 0.0967679333809167}, {"epochs": 76, "loss_train_training": 0.10310386623377385, "steps": 68326, "loss_test": 0.10494582529204306, "time": 8374.765563964844, "loss_train": 0.09677274505077951}, {"epochs": 77, "loss_train_training": 0.1030900198156419, "steps": 68372, "loss_test": 0.10486844381030835, "time": 8482.466593027115, "loss_train": 0.09669993664162785}, {"epochs": 78, "loss_train_training": 0.1029439992878748, "steps": 68418, "loss_test": 0.1048108986844779, "time": 8588.798345088959, "loss_train": 0.09664295675558539}, {"epochs": 79, "loss_train_training": 0.10273699575792188, "steps": 68464, "loss_test": 0.10505016534347994, "time": 8696.22249007225, "loss_train": 0.09666731268364731}, {"epochs": 80, "loss_train_training": 0.10318389340587285, "steps": 68510, "loss_test": 0.10511887576086563, "time": 8802.771854162216, "loss_train": 0.09669658255599492}, {"loss_train_training": 0.10320215607466905, "loss_test": 0.10476567160030673, "loss_train": 0.09649292847504748, "significance_test": 1.8849011034138583, "epochs": 81, "steps": 68533, "time": 8909.1377120018, "significance_train": 2.2357507774127825}, {"epochs": 82, "loss_train_training": 0.10297007567208746, "steps": 68556, "loss_test": 0.10501285496094061, "time": 9070.094628095627, "loss_train": 0.0965494251230893}, {"epochs": 83, "loss_train_training": 0.1033974218627681, "steps": 68579, "loss_test": 0.10484739606796853, "time": 9177.917823076248, "loss_train": 0.09652990093611157}, {"epochs": 84, "loss_train_training": 0.10280114833427512, "steps": 68602, "loss_test": 0.10475806333443773, "time": 9286.266747951508, "loss_train": 0.0964382022398307}, {"epochs": 85, "loss_train_training": 0.1028345599770546, "steps": 68625, "loss_test": 0.10476231411553263, "time": 9395.653959035873, "loss_train": 0.09640176429582369}, {"epochs": 86, "loss_train_training": 0.10267529474652332, "steps": 68648, "loss_test": 0.10501542270444132, "time": 9504.228811979294, "loss_train": 0.09646663377054562}, {"epochs": 87, "loss_train_training": 0.10289566218852997, "steps": 68671, "loss_test": 0.10481995037266427, "time": 9613.186918020248, "loss_train": 0.09638239937656357}, {"epochs": 88, "loss_train_training": 0.10259106884831967, "steps": 68694, "loss_test": 0.10485533016581598, "time": 9721.267765045166, "loss_train": 0.09637017664046994}, {"epochs": 89, "loss_train_training": 0.10266730124535768, "steps": 68717, "loss_test": 0.1048428891264075, "time": 9829.367764949799, "loss_train": 0.09633805765523323}, {"epochs": 90, "loss_train_training": 0.10257104395524315, "steps": 68740, "loss_test": 0.10493177219094398, "time": 9938.428414106369, "loss_train": 0.09636234267261287}, {"epochs": 91, "loss_train_training": 0.10277174704748651, "steps": 68763, "loss_test": 0.10478306040269159, "time": 10046.972661018372, "loss_train": 0.09628512954668811}, {"epochs": 92, "loss_train_training": 0.10250152453132298, "steps": 68786, "loss_test": 0.10487194018907471, "time": 10155.231755971909, "loss_train": 0.09629577660430647}, {"epochs": 93, "loss_train_training": 0.10289278367291325, "steps": 68809, "loss_test": 0.10487282012675819, "time": 10264.575585126877, "loss_train": 0.09632807895235578}, {"epochs": 94, "loss_train_training": 0.10264594010684801, "steps": 68832, "loss_test": 0.10473489001680036, "time": 10372.890242099762, "loss_train": 0.09625564941222481}, {"epochs": 95, "loss_train_training": 0.10278539197600406, "steps": 68855, "loss_test": 0.10501621669775159, "time": 10480.994270086288, "loss_train": 0.09634375709478936}, {"epochs": 96, "loss_train_training": 0.10252635861220567, "steps": 68878, "loss_test": 0.10482943682079245, "time": 10590.195966005325, "loss_train": 0.09622584543530166}, {"epochs": 97, "loss_train_training": 0.10263028805670531, "steps": 68901, "loss_test": 0.10477929178153761, "time": 10698.313682079315, "loss_train": 0.09621151872901307}, {"epochs": 98, "loss_train_training": 0.10251975610204365, "steps": 68924, "loss_test": 0.10488413266133798, "time": 10807.81666302681, "loss_train": 0.09618735203328785}, {"epochs": 99, "loss_train_training": 0.10278324296940929, "steps": 68947, "loss_test": 0.10475379008593881, "time": 10916.176347970963, "loss_train": 0.09616964204999999}, {"epochs": 100, "loss_train_training": 0.10258067917564641, "steps": 68970, "loss_test": 0.10485821542351874, "time": 11024.333833932877, "loss_train": 0.0961838093930522}, {"loss_train_training": 0.10291842176862386, "loss_test": 0.10488048084184276, "loss_train": 0.09614178929364535, "significance_test": 1.8871596322839752, "epochs": 101, "steps": 68993, "time": 11133.206625938416, "significance_train": 2.2405282206058503}, {"epochs": 102, "loss_train_training": 0.10266992287791293, "steps": 69016, "loss_test": 0.10475426367527116, "time": 11292.87965798378, "loss_train": 0.09614657370025763}, {"epochs": 103, "loss_train_training": 0.10241888107165047, "steps": 69039, "loss_test": 0.10476083301131765, "time": 11401.602961063385, "loss_train": 0.09616033607031735}, {"epochs": 104, "loss_train_training": 0.10259101766607036, "steps": 69062, "loss_test": 0.10479354499698586, "time": 11510.084291934967, "loss_train": 0.09606370248394774}, {"epochs": 105, "loss_train_training": 0.10251136091740234, "steps": 69085, "loss_test": 0.1048835812256893, "time": 11618.490520954132, "loss_train": 0.09613100865813409}, {"epochs": 106, "loss_train_training": 0.10279479298902594, "steps": 69108, "loss_test": 0.10483408178520424, "time": 11727.856930971146, "loss_train": 0.09612253950146732}, {"epochs": 107, "loss_train_training": 0.10267973691225052, "steps": 69131, "loss_test": 0.10477381220912653, "time": 11836.207746982574, "loss_train": 0.09606102771741798}, {"epochs": 108, "loss_train_training": 0.10258578833030618, "steps": 69154, "loss_test": 0.104828766186376, "time": 11944.21438908577, "loss_train": 0.09602679610707895}, {"epochs": 109, "loss_train_training": 0.10219630858172542, "steps": 69177, "loss_test": 0.1047477295512892, "time": 12053.843570947647, "loss_train": 0.09594814798579746}, {"epochs": 110, "loss_train_training": 0.10266472787960716, "steps": 69200, "loss_test": 0.1047144996344139, "time": 12162.094772100449, "loss_train": 0.09594731482971866}, {"epochs": 111, "loss_train_training": 0.10224179858746736, "steps": 69223, "loss_test": 0.10477993999992109, "time": 12270.361601114273, "loss_train": 0.09593101694532534}, {"epochs": 112, "loss_train_training": 0.1022438429619955, "steps": 69246, "loss_test": 0.10488394579421907, "time": 12379.653643131256, "loss_train": 0.09594348304171955}, {"epochs": 113, "loss_train_training": 0.10263681411743164, "steps": 69269, "loss_test": 0.10477231153285378, "time": 12487.611691951752, "loss_train": 0.09591417205880422}, {"epochs": 114, "loss_train_training": 0.10247077566126118, "steps": 69292, "loss_test": 0.10480201024263372, "time": 12596.771008968353, "loss_train": 0.09597507478234077}, {"epochs": 115, "loss_train_training": 0.10234061822943065, "steps": 69315, "loss_test": 0.10464077144181948, "time": 12705.290380954742, "loss_train": 0.09596757355215846}, {"epochs": 116, "loss_train_training": 0.10240995495215706, "steps": 69338, "loss_test": 0.10473123472202317, "time": 12813.13410615921, "loss_train": 0.09583673953880482}, {"epochs": 117, "loss_train_training": 0.10261361884034198, "steps": 69361, "loss_test": 0.10468272216970928, "time": 12922.546648025513, "loss_train": 0.09586098818591988}, {"epochs": 118, "loss_train_training": 0.10248670435470084, "steps": 69384, "loss_test": 0.10487101426595255, "time": 13030.67984008789, "loss_train": 0.09581865069358464}, {"epochs": 119, "loss_train_training": 0.10241029184797536, "steps": 69407, "loss_test": 0.10482495538712033, "time": 13138.651741027832, "loss_train": 0.09584332549054532}, {"epochs": 120, "loss_train_training": 0.10261636940033539, "steps": 69430, "loss_test": 0.10472513388771902, "time": 13248.150407075882, "loss_train": 0.09580172148850462}, {"loss_train_training": 0.10216689312999899, "loss_test": 0.10488687225056961, "loss_train": 0.09580282127284684, "significance_test": 1.8874406742651757, "epochs": 121, "steps": 69441, "time": 13356.293051958084, "significance_train": 2.2595114807471224}, {"epochs": 122, "loss_train_training": 0.10173826935616406, "steps": 69452, "loss_test": 0.10488555945738647, "time": 13516.033293008804, "loss_train": 0.09576839089247045}, {"epochs": 123, "loss_train_training": 0.10241190208630128, "steps": 69463, "loss_test": 0.10475853800256196, "time": 13623.167824983597, "loss_train": 0.09571480301770117}, {"epochs": 124, "loss_train_training": 0.10241193595257672, "steps": 69474, "loss_test": 0.1048456780426713, "time": 13730.350310087204, "loss_train": 0.09576595308493405}, {"epochs": 125, "loss_train_training": 0.1021151535890319, "steps": 69485, "loss_test": 0.1048633612692124, "time": 13838.68022108078, "loss_train": 0.09572789505977873}, {"epochs": 126, "loss_train_training": 0.10193735632029446, "steps": 69496, "loss_test": 0.1048720696697876, "time": 13945.666686058044, "loss_train": 0.09569194980598644}, {"epochs": 127, "loss_train_training": 0.1021114865487272, "steps": 69507, "loss_test": 0.10490883579995923, "time": 14052.842072963715, "loss_train": 0.09569759434947755}, {"epochs": 128, "loss_train_training": 0.10252618383277547, "steps": 69518, "loss_test": 0.10475888594327552, "time": 14161.32822394371, "loss_train": 0.09565530486400287}, {"epochs": 129, "loss_train_training": 0.10183140635490417, "steps": 69529, "loss_test": 0.10481387503077583, "time": 14268.200582027435, "loss_train": 0.09567118463673044}, {"epochs": 130, "loss_train_training": 0.10263914208520543, "steps": 69540, "loss_test": 0.10476567441240711, "time": 14375.534239053726, "loss_train": 0.09565896878577418}, {"epochs": 131, "loss_train_training": 0.10219737345522101, "steps": 69551, "loss_test": 0.10486430640819913, "time": 14483.869735002518, "loss_train": 0.0956706597345715}, {"epochs": 132, "loss_train_training": 0.1022839065302502, "steps": 69562, "loss_test": 0.10484646520827486, "time": 14590.625008106232, "loss_train": 0.09567619712269235}, {"epochs": 133, "loss_train_training": 0.10230121829292992, "steps": 69573, "loss_test": 0.10483120646717929, "time": 14698.540981054306, "loss_train": 0.09563029548019213}, {"epochs": 134, "loss_train_training": 0.1019918525760824, "steps": 69584, "loss_test": 0.1048197172372565, "time": 14804.622806072235, "loss_train": 0.09563156871307144}, {"epochs": 135, "loss_train_training": 0.10190307823094455, "steps": 69595, "loss_test": 0.10484699863899202, "time": 14908.23509812355, "loss_train": 0.09559809352496978}, {"epochs": 136, "loss_train_training": 0.10176302628083662, "steps": 69606, "loss_test": 0.10477881729971077, "time": 15012.674873113632, "loss_train": 0.09560027136185484}, {"epochs": 137, "loss_train_training": 0.10248203846541318, "steps": 69617, "loss_test": 0.10473169400390123, "time": 15115.948408126831, "loss_train": 0.0955957815168986}, {"epochs": 138, "loss_train_training": 0.10208409889177843, "steps": 69628, "loss_test": 0.10486297410361317, "time": 15218.830824136734, "loss_train": 0.0955961654855218}, {"epochs": 139, "loss_train_training": 0.10225808891383084, "steps": 69639, "loss_test": 0.10480931487345663, "time": 15323.3011200428, "loss_train": 0.09555485817130138}, {"epochs": 140, "loss_train_training": 0.10249718549576672, "steps": 69650, "loss_test": 0.10469121752776257, "time": 15426.467970132828, "loss_train": 0.095560474219404}, {"loss_train_training": 0.10243893550200896, "loss_test": 0.104863142349967, "loss_train": 0.09556377623305073, "significance_test": 1.8821055519923673, "epochs": 141, "steps": 69661, "time": 15529.481641054153, "significance_train": 2.2636044504095914}, {"epochs": 142, "loss_train_training": 0.10192936591126701, "steps": 69672, "loss_test": 0.10479488066173313, "time": 15683.299129962921, "loss_train": 0.0955325424915664}, {"epochs": 143, "loss_train_training": 0.10211546990004453, "steps": 69683, "loss_test": 0.10485596558352593, "time": 15786.17545413971, "loss_train": 0.09552146047491639}, {"epochs": 144, "loss_train_training": 0.10245108265768398, "steps": 69694, "loss_test": 0.10474972369686886, "time": 15889.35629105568, "loss_train": 0.09549651211741529}, {"epochs": 145, "loss_train_training": 0.10176686062054201, "steps": 69705, "loss_test": 0.10480723042222603, "time": 15993.057213068008, "loss_train": 0.09551901302164935}, {"epochs": 146, "loss_train_training": 0.10212438282641498, "steps": 69716, "loss_test": 0.10482143910021818, "time": 16096.04221200943, "loss_train": 0.09552756833749003}, {"epochs": 147, "loss_train_training": 0.10204848782582716, "steps": 69727, "loss_test": 0.10483634583702695, "time": 16200.11741399765, "loss_train": 0.09551268988815072}, {"epochs": 148, "loss_train_training": 0.10173016109249809, "steps": 69738, "loss_test": 0.10491882480357011, "time": 16303.19218802452, "loss_train": 0.09550115879804015}, {"epochs": 149, "loss_train_training": 0.10226534645665776, "steps": 69749, "loss_test": 0.10472767408055823, "time": 16406.2874751091, "loss_train": 0.09543390241779859}, {"epochs": 150, "loss_train_training": 0.10221138190139424, "steps": 69760, "loss_test": 0.10493666018990157, "time": 16510.214632987976, "loss_train": 0.09548633786734884}, {"epochs": 151, "loss_train_training": 0.10194357620044188, "steps": 69771, "loss_test": 0.10482583511251144, "time": 16613.339355945587, "loss_train": 0.09548550347026194}, {"epochs": 152, "loss_train_training": 0.10229734940962358, "steps": 69782, "loss_test": 0.10480692654734526, "time": 16716.444327116013, "loss_train": 0.09547097987111618}, {"epochs": 153, "loss_train_training": 0.10236859931187196, "steps": 69793, "loss_test": 0.10480313806911706, "time": 16820.29512500763, "loss_train": 0.09542600951923476}, {"epochs": 154, "loss_train_training": 0.10229546441273256, "steps": 69804, "loss_test": 0.10469455089630787, "time": 16923.25789499283, "loss_train": 0.09540147146166024}, {"epochs": 155, "loss_train_training": 0.10220154442570427, "steps": 69815, "loss_test": 0.10476411965387666, "time": 17026.15938615799, "loss_train": 0.09540840062854766}, {"epochs": 156, "loss_train_training": 0.1016905429688367, "steps": 69826, "loss_test": 0.10483459504783577, "time": 17129.937268018723, "loss_train": 0.09537989224290791}, {"epochs": 157, "loss_train_training": 0.10171757638454437, "steps": 69837, "loss_test": 0.10493312987251552, "time": 17233.052675962448, "loss_train": 0.09540743297703796}, {"epochs": 158, "loss_train_training": 0.10206470706246117, "steps": 69848, "loss_test": 0.1048287825149404, "time": 17336.23647594452, "loss_train": 0.09539759249091145}, {"epochs": 159, "loss_train_training": 0.10228892212564294, "steps": 69859, "loss_test": 0.10489764760217987, "time": 17440.333883047104, "loss_train": 0.09537937094667955}, {"epochs": 160, "loss_train_training": 0.10214045508341356, "steps": 69870, "loss_test": 0.10473140626974015, "time": 17543.36928510666, "loss_train": 0.09532212317288928}, {"loss_train_training": 0.10187402665615082, "loss_test": 0.1048362586442755, "loss_train": 0.09533852438454238, "significance_test": 1.8716346124891665, "epochs": 161, "steps": 69875, "time": 17646.431265115738, "significance_train": 2.273946260480398}, {"epochs": 162, "loss_train_training": 0.10181272476911545, "steps": 69880, "loss_test": 0.10489024358293432, "time": 17795.993917942047, "loss_train": 0.09534503227784473}, {"epochs": 163, "loss_train_training": 0.10176965743303298, "steps": 69885, "loss_test": 0.1048875434494486, "time": 17894.77526807785, "loss_train": 0.09532097172567248}, {"epochs": 164, "loss_train_training": 0.10222977995872498, "steps": 69890, "loss_test": 0.10483439200750343, "time": 17994.534759044647, "loss_train": 0.0953006242966978}, {"epochs": 165, "loss_train_training": 0.10226390212774276, "steps": 69895, "loss_test": 0.10473333150539864, "time": 18103.252951145172, "loss_train": 0.09529395413051621}, {"epochs": 166, "loss_train_training": 0.1018998771905899, "steps": 69900, "loss_test": 0.10478500618119677, "time": 18215.597701072693, "loss_train": 0.09530398906385518}, {"epochs": 167, "loss_train_training": 0.10203321874141694, "steps": 69905, "loss_test": 0.1048327685590808, "time": 18328.399690151215, "loss_train": 0.09533276657681768}, {"epochs": 168, "loss_train_training": 0.10170423686504364, "steps": 69910, "loss_test": 0.10482973612860184, "time": 18440.636492967606, "loss_train": 0.09532736262118119}, {"epochs": 169, "loss_train_training": 0.10181892812252044, "steps": 69915, "loss_test": 0.10478930589599493, "time": 18552.646970033646, "loss_train": 0.09531845942573217}, {"epochs": 170, "loss_train_training": 0.1026176780462265, "steps": 69920, "loss_test": 0.1047154309069327, "time": 18665.11062502861, "loss_train": 0.09531721196401957}, {"epochs": 171, "loss_train_training": 0.10265635997056961, "steps": 69925, "loss_test": 0.10473702665543991, "time": 18777.161371946335, "loss_train": 0.09532224620254245}, {"epochs": 172, "loss_train_training": 0.1016714707016945, "steps": 69930, "loss_test": 0.10486562774290124, "time": 18889.496749162674, "loss_train": 0.09534721741072182}, {"epochs": 173, "loss_train_training": 0.1021781325340271, "steps": 69935, "loss_test": 0.10486165692315731, "time": 19001.733184099197, "loss_train": 0.09532369303111045}, {"epochs": 174, "loss_train_training": 0.10190963447093963, "steps": 69940, "loss_test": 0.10475508192809212, "time": 19113.6937251091, "loss_train": 0.0952637723071965}, {"epochs": 175, "loss_train_training": 0.10224895775318146, "steps": 69945, "loss_test": 0.10471027289527639, "time": 19226.421760082245, "loss_train": 0.09523811166267077}, {"epochs": 176, "loss_train_training": 0.10169237107038498, "steps": 69950, "loss_test": 0.10469740717022082, "time": 19338.36089515686, "loss_train": 0.09524331562744234}, {"epochs": 177, "loss_train_training": 0.10199877172708512, "steps": 69955, "loss_test": 0.1048411477703014, "time": 19450.414824962616, "loss_train": 0.0952868477635589}, {"epochs": 178, "loss_train_training": 0.10199023634195328, "steps": 69960, "loss_test": 0.10484429584194868, "time": 19562.96235895157, "loss_train": 0.09529049232437964}, {"epochs": 179, "loss_train_training": 0.10198668837547302, "steps": 69965, "loss_test": 0.10476519985754673, "time": 19675.32575392723, "loss_train": 0.09524355130324594}, {"epochs": 180, "loss_train_training": 0.10169572532176971, "steps": 69970, "loss_test": 0.10478388391794975, "time": 19787.517935991287, "loss_train": 0.09523457960046151}, {"loss_train_training": 0.10153810977935791, "loss_test": 0.1047595092764119, "loss_train": 0.09520966419182463, "significance_test": 1.8698092378407825, "epochs": 181, "steps": 69975, "time": 19900.01265311241, "significance_train": 2.261186795939507}, {"epochs": 182, "loss_train_training": 0.10284870564937591, "steps": 69980, "loss_test": 0.10471747837782082, "time": 20068.73413515091, "loss_train": 0.09520390907547503}, {"epochs": 183, "loss_train_training": 0.10255305469036102, "steps": 69985, "loss_test": 0.10470766379499173, "time": 20181.081797122955, "loss_train": 0.09521179880797496}, {"epochs": 184, "loss_train_training": 0.10149761140346528, "steps": 69990, "loss_test": 0.10477158687714408, "time": 20293.20145702362, "loss_train": 0.09523696925840149}, {"epochs": 185, "loss_train_training": 0.10180371850728989, "steps": 69995, "loss_test": 0.10482130074221777, "time": 20405.960210084915, "loss_train": 0.09525052243727133}, {"epochs": 186, "loss_train_training": 0.10192583501338959, "steps": 70000, "loss_test": 0.10476506096015037, "time": 20518.264058113098, "loss_train": 0.09521521289957871}, {"epochs": 187, "loss_train_training": 0.10194822549819946, "steps": 70005, "loss_test": 0.10477524362609313, "time": 20630.139205932617, "loss_train": 0.0952133570139515}, {"epochs": 188, "loss_train_training": 0.10151975005865096, "steps": 70010, "loss_test": 0.10476502691569393, "time": 20739.240792036057, "loss_train": 0.09520998845683691}, {"epochs": 189, "loss_train_training": 0.10164530873298645, "steps": 70015, "loss_test": 0.10476331135342157, "time": 20847.667361021042, "loss_train": 0.0952275905026316}, {"epochs": 190, "loss_train_training": 0.10264137387275696, "steps": 70020, "loss_test": 0.10477759131925712, "time": 20956.153308153152, "loss_train": 0.09523059373680606}, {"epochs": 191, "loss_train_training": 0.10192060023546219, "steps": 70025, "loss_test": 0.1047711216990463, "time": 21065.117388010025, "loss_train": 0.09522118012861373}, {"epochs": 192, "loss_train_training": 0.10140976309776306, "steps": 70030, "loss_test": 0.10484769183860314, "time": 21173.3000330925, "loss_train": 0.09524067760748084}, {"epochs": 193, "loss_train_training": 0.10144433379173279, "steps": 70035, "loss_test": 0.10487492008771117, "time": 21281.833059072495, "loss_train": 0.09524145125300046}, {"epochs": 194, "loss_train_training": 0.10119315981864929, "steps": 70040, "loss_test": 0.10486570585380939, "time": 21390.941030979156, "loss_train": 0.09521841332854418}, {"epochs": 195, "loss_train_training": 0.10173528641462326, "steps": 70045, "loss_test": 0.10480695375171642, "time": 21499.39481496811, "loss_train": 0.09517577156332258}, {"epochs": 196, "loss_train_training": 0.10192049294710159, "steps": 70050, "loss_test": 0.10481641917423389, "time": 21607.997188091278, "loss_train": 0.09518171509332078}, {"epochs": 197, "loss_train_training": 0.10234518498182296, "steps": 70055, "loss_test": 0.1048309898002137, "time": 21716.064641952515, "loss_train": 0.09519371109488078}, {"epochs": 198, "loss_train_training": 0.1020148128271103, "steps": 70060, "loss_test": 0.10482195005981779, "time": 21824.368772029877, "loss_train": 0.09518390263376678}, {"epochs": 199, "loss_train_training": 0.10185030251741409, "steps": 70065, "loss_test": 0.10484510392825462, "time": 21933.04684305191, "loss_train": 0.09517325031285478}, {"loss_train_training": 0.1019512191414833, "loss_test": 0.10481698768116084, "loss_train": 0.0951510206648966, "significance_test": 1.8711259409211707, "epochs": 200, "steps": 70070, "time": 22041.353024959564, "significance_train": 2.274220233843042}]